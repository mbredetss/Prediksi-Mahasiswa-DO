# -*- coding: utf-8 -*-
"""Untitled48.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19wEiHhD2bYnHG8l7DddMWVggi4gfg1z2

# **Domain Proyek**
Pada setiap pergantian semester, terdapat mahasiswa yang harus keluar dari kampus atau tidak lulus mata kuliah tertentu. Untuk mengatasi permasalahan ini, dikembangkan sebuah model prediksi yang dapat memperkirakan hasil akhir nilai ujian mahasiswa. Dengan adanya model ini, mahasiswa yang diprediksi tidak lulus dapat memperoleh intervensi sejak dini.

Berdasarkan artikel dari [Departement of Communications UII](https://communication.uii.ac.id/beragam-alasan-mahasiswa-tidak-lulus-lulus-bagaimana-mengantisipasinya/) kasus DO di indonesia ada 601.333 mahasiswa putus kuliah.

Diharapkan bahwa langkah ini dapat membantu mengurangi jumlah mahasiswa yang harus mengulang mata kuliah di semester berikutnya. Model prediksi ini akan menggunakan berbagai faktor yang memengaruhi nilai ujian sebagai dasar analisis untuk memprediksi performa akademik mahasiswa.

# **Business Understanding**

## **Problem Statement dan Goals**
Setiap semester, ratusan ribu mahasiswa di Indonesia tidak lulus mata kuliah atau bahkan mengalami putus kuliah (DO) akibat ketidaktahuan terhadap risiko akademik yang dihadapi. Sistem kampus saat ini masih memiliki keterbatasan dalam mengidentifikasi mahasiswa berisiko gagal secara real-time dan memberikan intervensi dini. Akibatnya, banyak mahasiswa baru menyadari ketidaklulusan setelah proses evaluasi akhir, yang berpotensi meningkatkan beban akademik dan finansial serta menurunkan motivasi belajar.

Untuk mengatasi permasalahan tersebut, dikembangkan sebuah model machine learning dengan tujuan:

* Memprediksi hasil akhir nilai ujian mahasiswa dengan akurasi tinggi berdasarkan faktor-faktor yang memengaruhi performa akademik.

* Mengidentifikasi faktor dominan (misalnya: kehadiran, nilai tugas, partisipasi kelas) yang memiliki korelasi signifikan dengan ketidaklulusan.

## **Metodologi**
Karena nilai ujian akhir yang diprediksi bersifat kontinu, model regresi akan digunakan untuk memprediksi hasil ujian setiap mahasiswa. Beberapa algoritma regresi yang akan diterapkan meliputi:
* Linear Regression, algoritma dasar untuk regresi yang mudah diinterpretasi dan cocok untuk baseline model/
* Decision Tree Regressor, karena algoritma ini dapat menangani hubungan non-linear dan interaksi antar fitur dan mudah diinterpretasi tetapi rentan overfitting.
* Random Forest Regressor, untuk mengatasi masalah dari algoritma decission tree, algoritma random forrest bisa mengurangi resiko overfitting.

## **Metrik**
Metrik yang akan di gunakan adalah MAE dan MSE

# **Data Understanding**
Dataset ini memberikan gambaran menyeluruh tentang berbagai faktor yang mempengaruhi kinerja siswa dalam ujian. Data ini mencakup informasi mengenai kebiasaan belajar, kehadiran, keterlibatan orang tua, dan aspek-aspek lain yang memengaruhi keberhasilan akademik. Sumber dataset: [Kaggle](https://www.kaggle.com/datasets/lainguyn123/student-performance-factors). Dataset ini terdiri dari 20 fitur dan 6000 baris dengan kondisi dataset terbilang cukup bersih.

**Variabel-variabel pada Student Performance Factor dataset adalah sebagai berikut:**


* Hours_Studied: Jumlah jam belajar per minggu.

* Attendance: Persentase kehadiran di kelas.

* Parental_Involvement: Tingkat keterlibatan orang tua dalam pendidikan siswa (Rendah, Sedang, Tinggi).

* Access_to_Resources: Ketersediaan sumber daya pendidikan (Rendah, Sedang, Tinggi).

* Extracurricular_Activities: Partisipasi dalam kegiatan ekstrakurikuler (Ya, Tidak).

* Sleep_Hours: Rata-rata jam tidur per malam.

* Previous_Scores: Nilai dari ujian sebelumnya.

* Motivation_Level: Tingkat motivasi siswa (Rendah, Sedang, Tinggi).

* Internet_Access: Ketersediaan akses internet (Ya, Tidak).

* Tutoring_Sessions: Jumlah sesi bimbingan belajar yang dihadiri per bulan.

* Family_Income: Tingkat pendapatan keluarga (Rendah, Sedang, Tinggi).

* Teacher_Quality: Kualitas guru (Rendah, Sedang, Tinggi).

* School_Type: Jenis sekolah yang dihadiri (Negeri, Swasta).

* Peer_Influence: Pengaruh teman sebaya terhadap performa akademik (Positif, Netral, Negatif).

* Physical_Activity: Rata-rata jam aktivitas fisik per minggu.

* Learning_Disabilities: Adanya gangguan belajar (Ya, Tidak).

* Parental_Education_Level: Tingkat pendidikan tertinggi orang tua (SMA, Perguruan Tinggi, Pascasarjana).

* Distance_from_Home: Jarak dari rumah ke sekolah (Dekat, Sedang, Jauh).

* Gender: Jenis kelamin siswa (Laki-laki, Perempuan).

* Exam_Score: Nilai ujian akhir.

Langkah pertama dalam pemrosesan data adalah mengunduh dataset dari tautan yang telah disediakan. Sebelum itu, diperlukan pengunggahan file JSON dari Kaggle untuk mengakses API Kaggle.
"""

# Pertama, install package kaggle
!pip install kaggle

# Upload file kaggle.json Anda (dapatkan dari profil Kaggle Anda)
from google.colab import files
files.upload()

# Unduh dataset
!kaggle datasets download -d lainguyn123/student-performance-factors

"""Setelah dataset berhasil diunduh, perlu dilakukan ekstraksi karena masih dalam format .zip."""

# Unzip dataset
import zipfile
with zipfile.ZipFile('student-performance-factors.zip', 'r') as zip_ref:
    zip_ref.extractall('.')

"""## **Menangani Missing Value dan Outliers**

Selanjutnya, dilakukan pengecekan terhadap dataset untuk mengidentifikasi adanya missing values, data tidak valid, atau outliers guna mempermudah proses visualisasi.
"""

import pandas as pd

StudentPerformanceFactors = pd.read_csv('/content/StudentPerformanceFactors.csv')

StudentPerformanceFactors.info()

# 1. Cek Missing Value
print("Missing Values:")
print(StudentPerformanceFactors.isnull().sum())

"""Hasil pengecekan menunjukkan bahwa beberapa fitur memiliki missing values atau data yang hilang. Karena jumlahnya relatif kecil, keputusan yang diambil adalah menghapus data yang mengandung missing values."""

StudentPerformanceFactors = StudentPerformanceFactors.dropna()

StudentPerformanceFactors.info()

"""Langkah selanjutnya adalah mengecek keberadaan data tidak valid pada fitur numerik.

Perhatikan pada bagian code dibwh ini:

```
# valid_ranges = {
    'Hours_Studied': (0, 168),  # Maksimal 24x7 jam
    'Attendance': (0, 100),     # Persentase
    'Sleep_Hours': (0, 24),     # Jam tidur harian
    'Previous_Scores': (0, 100),# Nilai ujian
    'Tutoring_Sessions': (0, 31),# Maksimal 1x sehari
    'Physical_Activity': (0, 168) # Jam per minggu
}
```
Code diatas merupakan batas valid dari fitur numerik. Berikut adalah alasan setiap fitur di beri batas valid:
* Hours_Studied: (0, 168)

  Fitur ini merupakan jumlah jam belajar per minggu. Nilai yang diluar rentang ini di anggap tidak valid karena tidak mungkin secara logis. **Contoh**: jumlah jam belajar per minggu adalah 169. Ini adalah tidak logis, karena dalam seminggu hanya ada 168 jam

* Attendance: (0, 100)

  Nilai di luar rentang ini tidak memiliki makna dalam konteks persentase.

* Sleep_Hours: (0, 24)

  Batas maksimum jam tidur dalam sehari adalah 24 jam (satu hari penuh). Nilai 0 mungkin menandakan data error (karena manusia tetap butuh tidur minimal 1-2 jam).

* Previous_Scores: (0, 100)

  Nilai ujian biasanya dalam skala 0-100. Nilai di atas 100 atau negatif tidak valid dalam sistem penilaian standar.

* Tutoring_Sessions: (0, 31)

  Jumlah maksimum sesi bimbingan dalam sebulan = 31 (asumsi 1 sesi/hari di bulan dengan 31 hari).Nilai negatif tidak mungkin karena merepresentasikan jumlah sesi.

* Physical_Activity: (0, 168)

  Sama seperti Hours_Studied: 168 jam = total jam dalam seminggu. Nilai 168 berarti aktivitas fisik dilakukan 24 jam non-stop (tidak realistis, tetapi tetap dipertahankan sebagai batas teknis).


"""

# Validasi Data Numerik
numeric_columns = ['Hours_Studied', 'Attendance', 'Sleep_Hours',
                 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity']

# Batas valid untuk setiap kolom numerik
valid_ranges = {
    'Hours_Studied': (0, 168),  # Maksimal 24x7 jam
    'Attendance': (0, 100),     # Persentase
    'Sleep_Hours': (0, 24),     # Jam tidur harian
    'Previous_Scores': (0, 100),# Nilai ujian
    'Tutoring_Sessions': (0, 31),# Maksimal 1x sehari
    'Physical_Activity': (0, 168) # Jam per minggu
}

# Cek data tidak valid
print("\nInvalid Data:")
for col, (min_val, max_val) in valid_ranges.items():
    invalid = StudentPerformanceFactors[(StudentPerformanceFactors[col] < min_val) | (StudentPerformanceFactors[col] > max_val)]
    if not invalid.empty:
        print(f"{col}: {len(invalid)} data tidak valid")
        print(f"  Nilai ekstrim: Min {invalid[col].min()} - Max {invalid[col].max()}")

"""Hasil menunjukkan tidak ada data yang tidak valid.

Selanjutnya, dilakukan analisis terhadap keberadaan outliers dalam dataset menggunakan boxplot.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Boxplot untuk Deteksi Outlier
plt.figure(figsize=(15,10))
for i, col in enumerate(numeric_columns, 1):
    plt.subplot(2,3,i)
    sns.boxplot(y=StudentPerformanceFactors[col])
    plt.title(col)
plt.tight_layout()
plt.show()

"""Lalu menangani outliers dengan menggunakan metode IQR. IQR adalah singkatan dari Inter Quartile Range. Inter Quartile Range (IQR) adalah salah satu prosedur yang paling banyak digunakan untuk deteksi dan penghapusan outlier. Hal ini dapat diterapkan dengan menemukan kuartil pertama dan ketiga (Q1 dan Q3) kemudian menghitung nilai IQRnya dengan mengurangi Q3 dan Q1.

Nilai outlier ini di ganti menjadi boundary.
"""

# 4. Penanganan Outlier
def handle_outliers(df, column):
    q1 = StudentPerformanceFactors[column].quantile(0.25)
    q3 = StudentPerformanceFactors[column].quantile(0.75)
    iqr = q3 - q1

    lower_bound = q1 - (1.5 * iqr)
    upper_bound = q3 + (1.5 * iqr)

    # Ganti outlier dengan nilai boundary
    StudentPerformanceFactors[column] = StudentPerformanceFactors[column].clip(lower=lower_bound, upper=upper_bound)
    return df

# Terapkan ke semua kolom numerik
for col in numeric_columns:
    df = handle_outliers(StudentPerformanceFactors, col)

"""Hasil setelah penanganan outlier"""

# Verifikasi hasil setelah penanganan
plt.figure(figsize=(15,10))
for i, col in enumerate(numeric_columns, 1):
    plt.subplot(2,3,i)
    sns.boxplot(y=StudentPerformanceFactors[col])
    plt.title(f'{col} (After Handling)')
plt.tight_layout()
plt.show()

"""## **Exploratory Data Analysis - Univariate Analysis**

Untuk analisis lebih lanjut, fitur numerik dan kategorikal perlu dipisahkan. Karena fitur numerik telah dipisahkan sebelumnya, maka tahap berikutnya adalah memisahkan fitur kategorikal.
"""

categorical_cols = ['Parental_Involvement', 'Extracurricular_Activities', 'Motivation_Level',
                   'Internet_Access', 'Family_Income', 'Teacher_Quality', 'School_Type',
                   'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level',
                   'Distance_from_Home', 'Gender', 'Access_to_Resources']

"""Agar proses analisis lebih efisien, dibuat sebuah fungsi yang dapat digunakan berulang kali pada fitur kategorikal."""

def analyze_categorical_feature(df, feature):
    """
    Menampilkan analisis fitur kategorikal yang terdiri dari:
    - Tabel jumlah sampel dan persentase
    - Visualisasi bar plot

    Parameter:
    df (DataFrame): DataFrame yang digunakan
    feature (str): Nama kolom fitur kategorikal yang ingin dianalisis
    """
    count = df[feature].value_counts()
    percent = 100 * df[feature].value_counts(normalize=True)
    df_result = pd.DataFrame({
        'jumlah sampel': count,
        'persentase': percent.round(1)
    })

    print(f"Analisis untuk fitur: {feature}")
    print(df_result)

    count.plot(kind='bar', title=feature)
    plt.show()  # Untuk memastikan plot ditampilkan jika menggunakan environment non-interaktif

"""### **Categorical Features**

#### **Fitur Parental_Involvement**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[0])

"""Terdapat tiga kategori tingkat keterlibatan orang tua dalam pendidikan siswa (Parental Involvement), yaitu medium, high, dan low. Berdasarkan data persentase, dapat disimpulkan bahwa 50% keterlibatan orang tua (Parental Involvement) termasuk dalam kategori medium. Hal ini menunjukkan bahwa setengah dari siswa mendapatkan perhatian dalam proses perkuliahan.

#### **Fitur Extracurricular_Activities**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[1])

"""Dari hasil persentase diatas, 59% mahasiswa memiliki aktivitas ekstrakurikuler.

#### **Fitur Motivation_Level**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[2])

"""Dari hasil tabel diatas, level motivasi di dominasi oleh medium yang memiliki persante 50% dari 2 level motivasi lainnya, seperti low dan medium

#### **Fitur Internet_Access**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[3])

"""Hasil dari visualisasi diatas menunjukkan bahwa hampir semua mahasiswa memiliki akses ke internet.

#### **Fitur Family_Income**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[4])

"""Dari tabel di atas, kita dapat melihat bahwa persentase mahasiswa dengan pendapatan keluarga tinggi hanya sedikit, yaitu 19%, sedangkan sisanya berada pada kategori medium dan low

#### **Fitur Teacher_Quality**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[5])

"""Disini kita bisa melihat, bahwa kealitas dari dosen/pengajar murid berkualitas tinggi.

#### **Fitur School_Type**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[6])

"""Dari hasil visualisasi diatas menunjukkan sekolah public (negeri) lebih banyak di bandingkan private (swasta)

#### **Fitur Peer_Influence**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[7])

"""Pengaruh teman sebaya cenderung didominasi oleh pengaruh positif dan netral, dengan persentase yang hampir seimbang (40.0% vs 39.1%). Namun, masih ada sebagian signifikan (20.9%) yang mengalami pengaruh negatif. Hal ini menunjukkan bahwa peer influence memiliki dampak beragam, dengan kecenderungan lebih ke arah positif/netral.

#### **Fitur Learning_Disabilities**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[8])

"""Ini menunjukkan sebagian besar mahasiswa tidak mengalami gangguan belajar

#### **Fitur Parental_Education_Level**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[9])

"""Hasil dari analisis diatas menunjukkan 50% pendidikan terakhir orang tua mahasiswa adalah SMA atau high school

#### **Fitur Distance_from_Home**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[10])

"""hasil diatas menunjukkan 59% mahasiswa memiliki jarak antar rumah ke sekolah yang dekat.

#### **Fitur Gender**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[11])

"""hasil diatas menunjukkan jumlah siswa laki laki dan perempuan seimbang dimana siswa laki-laki 58% dan perempuan 42%

#### **Fitur Access_to_Resources**
"""

analyze_categorical_feature(StudentPerformanceFactors, categorical_cols[12])

"""Grafik diatas menunjukkan 80% siswa memiliki ketersediaan sumber daya pendidikan yang memadai

### **Numerik Features**
"""

StudentPerformanceFactors.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari hasil histogram fitur target yaitu Exam_Score, kita bisa memperoleh informasi, antara lain:
* Sebagian besar siswa memiliki nilai di sekitar 65-70, dengan sedikit yang memiliki nilai lebih tinggi atau lebih rendah dari rentang ini. Distribusi relatif simetris dengan sedikit skewness ke kanan.

### **Exploratory Data Analysis - Multivariate Analysis**

#### **Categorical Features**
"""

cat_features = StudentPerformanceFactors.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="Exam_Score", kind="bar", dodge=False, height = 4, aspect = 3,  data=StudentPerformanceFactors, palette="Set3")
  plt.title("Rata-rata 'Exam_Score' Relatif terhadap - {}".format(col))

"""Kesimpulan yang diperoleh menunjukkan bahwa rata-rata hasil ujian siswa adalah 70. Faktor-faktor yang memengaruhi nilai ujian meliputi Parental_Involvement, Access_to_Resources, Extracurricular_Activities, Motivation_Level, Internet_Access, Family_Income, Teacher_Quality, School_Type, Peer_Influence, Learning_Disabilities, Parental_Education_Level, Distance_from_Home, Gender, dan Access_to_Resources.

#### **Numerik Features**
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(StudentPerformanceFactors, diag_kind = 'kde')

"""Dapat kita lihat pada fitur target (Exam_Score), fitur Hours_Studied, Attendance, Sleep_Hours, Previous_Scores, Tutoring_Sessions, Physical_Activity menunjukkan pola acak yang berarti memiliki korelasi yang lemah.
Selanjutnya, mengecek korelasi antara fitur target dengan fitur numerik.
"""

numeric_columns = ['Hours_Studied', 'Attendance', 'Sleep_Hours',
                 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity', 'Exam_Score']

plt.figure(figsize=(10, 8))
correlation_matrix = StudentPerformanceFactors[numeric_columns].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Berdasarkan hasil analisis korelasi, fitur Hours_Studied dan Attendance memiliki skor korelasi yang cukup tinggi (di atas 0.44) terhadap Exam_Score, sehingga fitur-fitur tersebut dianggap memiliki hubungan yang signifikan. Sementara itu, fitur Sleep_Hours dan Physical_Activity memiliki skor korelasi yang sangat kecil, sehingga fitur-fitur tersebut dihapus dari dataset."""

StudentPerformanceFactors.drop(['Sleep_Hours', 'Physical_Activity'], inplace=True, axis=1)
StudentPerformanceFactors.head()

"""# **Data Preparation**

Langkah berikutnya adalah tahap preprocessing data, yang mencakup pengecekan dan penanganan data duplikat serta penerapan feature engineering.

Tahap pertama dalam preprocessing adalah memeriksa keberadaan data duplikat.
"""

# Mengecek duplikasi data
duplikat = StudentPerformanceFactors.duplicated()

# Menampilkan jumlah data duplikat
print(f"Jumlah data duplikat: {duplikat.sum()}")

"""Dataset yang diambil dari Kaggle ini tergolong cukup bersih, sehingga tidak ditemukan data duplikat (jumlah duplikat = 0).

## Feature Encoding

Selanjutnya, dilakukan encoding pada fitur kategorikal. Encoding merupakan teknik untuk mengonversi data kategorikal menjadi bentuk numerik agar dapat diproses oleh mesin/komputer.

Metode Label Encoding digunakan dalam proses ini. Label Encoding mengubah kategori menjadi label numerik dan sesuai untuk variabel ordinal (kategori dengan tingkatan). Pada dataset yang digunakan, terdapat fitur kategorikal seperti "medium", "low", dan "high" yang memiliki hierarki ordinal, sehingga metode ini cocok untuk diterapkan.
"""

from sklearn.preprocessing import LabelEncoder

# Salin dataset ke variabel baru untuk menghindari modifikasi dataset asli
df_encoded = StudentPerformanceFactors.copy()

# Inisialisasi LabelEncoder
le = LabelEncoder()

# Lakukan label encoding untuk setiap kolom kategorikal
for col in categorical_cols:
    df_encoded[col] = le.fit_transform(df_encoded[col])

# Hasil dataset setelah encoding
df_encoded.head()

"""Selanjutnya, distribusi fitur numerik dianalisis menggunakan fungsi describe()."""

df_encoded.describe()

"""Berdasarkan hasil analisis deskriptif, terlihat bahwa fitur-fitur dalam dataset memiliki rentang skala yang berbeda. Oleh karena itu, dilakukan penyesuaian skala (scaling) agar rentang nilai setiap fitur menjadi seragam.

## Feature Scaling
Sebelum melakukan scaling, dataset dibagi menjadi data latih (training data) dan data uji (testing data) dengan rasio 80:20 untuk menghindari kebocoran data (data leakage).
"""

from sklearn.model_selection import train_test_split

# Pisahkan fitur dan target
X = df_encoded.drop('Exam_Score', axis=1)
y = df_encoded['Exam_Score']

# Split data dengan rasio 80:20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Setelah pemisahan dataset, dilakukan scaling pada fitur training dan testing menggunakan StandardScaler, yang menstandarisasi fitur dengan mean = 0 dan standar deviasi = 1. Metode ini cocok digunakan pada algoritma yang bergantung pada jarak (seperti SVM dan KNN) atau model linear."""

from sklearn.preprocessing import StandardScaler

# Scaling pada fitur numerik
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Fitting hanya pada data training
X_test_scaled = scaler.transform(X_test)        # Transform data testing

"""## Principal Component Analysis
Tahapan selanjutnya adalah Principal Component Analysis. PCA mentransformasi fitur menjadi komponen utama yang saling tegak lurus (tidak berkorelasi) dan mempertahankan varians data sambil mengurangi dimensi.

Code di bwh ini mengecek multikolinearitas dengan Variance Inflation Factor (VIF) dengan menghitung Variance Inflation Factor (VIF) untuk mendeteksi korelasi antar-fitur. Dengan mendeteksi apakah ada multikolinearitas tinggi, kita bisa mengurangi dimensi menggunakan PCA

"""

!pip install statsmodels

from statsmodels.stats.outliers_influence import variance_inflation_factor
import pandas as pd

# Hitung VIF untuk setiap fitur
vif_data = pd.DataFrame()
vif_data["feature"] = X_train.columns
vif_data["VIF"] = [variance_inflation_factor(X_train_scaled, i) for i in range(X_train_scaled.shape[1])]

print("VIF sebelum PCA:")
print(vif_data)

"""Jika ada fitur dengan VIF > 10, dilakukan reduksi dimensi dengan PCA."""

from sklearn.decomposition import PCA

# Handle multikolinearitas dengan PCA jika VIF > 10
if any(vif_data["VIF"] > 10):
    pca = PCA(n_components=0.95)
    X_train_pca = pca.fit_transform(X_train_scaled)
    X_test_pca = pca.transform(X_test_scaled)
    print(f"\nMenggunakan {pca.n_components_} komponen PCA.")
    print("Varians dipertahankan:", sum(pca.explained_variance_ratio_))
else:
    print("\nTidak ada multikolinearitas tinggi.")

"""# **Modelling**
Selanjutnya kita masuk pada tahapan modelling. Pada tahap ini, kita akan mengembangkan model machine learning dengan tiga algoritma. Kemudian, kita akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik. Ketiga algoritma yang akan kita gunakan, antara lain:

* Linear-Regression, kelebihan dari algoritma linear regression cepat dan mudah diinterpretasi (koefisien menunjukkan pengaruh fitur terhadap target) juga tidak rawan overfitting jika data benar-benar linear, tetapi tidak bisa menangkap hubungan non-linear antar fitur dan sensitif terhadap outlier dan multikolinearitas.
* Decision TreeRegressor, berbeda dengan linear regression, decission tree bisa menangkap hubungan non-linear dan interaksi kompleks antar fitur dan tidak memerlukan scaling data. Akan tetapi algoritma ini juga memiliki kekurangan seperti mudah overfitting jika tidak diatur kedalaman pohon (max_depth) dan kurang stabil (perubahan kecil pada data bisa mengubah struktur pohon).
* Random Forest Regressor, random forest regressor merupakan kombinasi dari banyak decission tree, algoritma ini memiliki kelebihan dapat mengurangi overfitting dengan menggabungkan banyak pohon (ensemble learning) dan lebih stabil dan akurat dibanding Decision Tree tunggal.
"""

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Gunakan data yang sudah di-scaling (atau PCA jika diperlukan)
# Jika menggunakan PCA, ganti X_train_scaled dengan X_train_pca dan X_test_scaled dengan X_test_pca

# Definisikan model-model yang akan digunakan
models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(random_state=42)
}

# Dictionary untuk menyimpan hasil evaluasi
results = {}

# Latih dan evaluasi setiap model
for name, model in models.items():
    # Training model
    model.fit(X_train_scaled, y_train)

    # Prediksi data training dan testing
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)

    # Hitung metrik evaluasi
    train_mae = mean_absolute_error(y_train, y_train_pred)
    train_mse = mean_squared_error(y_train, y_train_pred)
    test_mae = mean_absolute_error(y_test, y_test_pred)
    test_mse = mean_squared_error(y_test, y_test_pred)

    # Simpan hasil
    results[name] = {
        "Train MAE": train_mae,
        "Train MSE": train_mse,
        "Test MAE": test_mae,
        "Test MSE": test_mse
    }

# Tampilkan hasil evaluasi
for model_name, metrics in results.items():
    print(f"=== {model_name} ===")
    print(f"Train MAE: {metrics['Train MAE']:.4f}")
    print(f"Train MSE: {metrics['Train MSE']:.4f}")

"""Penjelasan code diatas:


```
models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(random_state=42)
}
```
Kode ini digunakan untuk mendefinisikan model-model yang akan digunakan. Parameter **random_state** pada Decision Tree dan Random Forest ditetapkan untuk memastikan reproduksibilitas hasil, sementara parameter lainnya dipertahankan sebagai nilai default.



```
results = {}
```
Selanjutnya, menyiapkan sebuah dictionary untuk menyimpan hasil evaluasi.

Setelah itu, melatih dan mengevaluasi ketiga algoritma machine learning, lalu menyimpan hasil evaluasinya ke dalam dictionary yang telah disiapkan sebelumnya.

Berdasarkan hasil evaluasi, dapat disimpulkan bahwa algoritma Random Forest menunjukkan performa terbaik dibandingkan dua algoritma lainnya. Sementara itu, Decision Tree teridentifikasi mengalami overfitting.

## Hyperparameter Tuning
Untuk meningkatkan kualitas model dari algoritma Random Forrest, perlu dilakukan hyperparameter tuning. Metode hyperparameter tuning yang akan digunakan adalah grid search. Grid search merupakan metode hyperparameter tuning yang mencoba semua kombinasi hyperparameter yang telah ditentukan dan mengevaluasi performa model untuk setiap kombinasi tersebut. Hasil akhirnya akan memilih kombinasi hyperparameter terbaik.

Evaluasi model pada tahapan gridsearch menggunakan cross-validation agar model robust.

Langkah pertama yang dilakukan mendefinisikan kombinasi hyperparameter.
"""

param_grid = {
    'n_estimators': [100, 200, 300],      # Coba jumlah pohon lebih besar
    'max_depth': [None, 10, 15, 20],      # Batasi kedalaman untuk hindari overfitting
    'min_samples_split': [2, 5, 10],      # Kontrol splitting node
    'max_features': ['sqrt', 0.5, 0.8]    # Cakupan fitur untuk split
}

"""Selanjutnya mengimplementasi GridSearchCV dengan cross-validaion"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# Inisialisasi model
rf = RandomForestRegressor(random_state=42)

# GridSearchCV dengan 5-fold cross-validation
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,                          # 5-fold cross-validation
    scoring='neg_mean_squared_error',  # Fokus minimalkan MSE
    n_jobs=-1,                      # Gunakan semua core CPU
    verbose=2                       # Tampilkan progress
)

# Fit pada data training yang sudah di-scaling
grid_search.fit(X_train_scaled, y_train)

# Ambil model terbaik
best_rf = grid_search.best_estimator_

"""Hasil dari GridSearch parameter terbaik adalah di bawah ini"""

print(best_rf)

# Prediksi data training
y_train_pred = best_rf.predict(X_train_scaled)

# Hitung MAE dan MSE untuk data training
train_mae = mean_absolute_error(y_train, y_train_pred)
train_mse = mean_squared_error(y_train, y_train_pred)

# Tampilkan hasil
print(f"=== Random Forrest ===")
print(f"Train MAE: {train_mae:.4f}")
print(f"Train MSE: {train_mse:.4f}")

"""Jika kita perhatikan kembali, hasil model yang diperoleh dari proses hyperparameter tuning menunjukkan peningkatan nilai MAE dan MSE dibandingkan sebelum dilakukan tuning. Berikut perbandingannya:

**Sebelum Tuning**

=== Random Forest ===

Train MAE: 0.4497

Train MSE: 0.8033

**Setelah Tuning**

=== Random Forrest ===

Train MAE: 0.5625

Train MSE: 1.7246

Hal ini umum terjadi dalam proses hyperparameter tuning.

# **Evaluation**

Metrik yang akan digunakan pada prediksi ini adalah MAE dan MSE. Berikut adalah penjelasan tiap metrik yang digunakan:

* Mean Absolute Error (MAE)

  MAE adalah salah satu metode evaluasi yang umum digunakan dalam data science. MAE menghitung rata-rata dari selisih absolut antara nilai prediksi dan nilai aktual.

  Dengan kata lain, MAE menghitung berapa rata-rata kesalahan absolut dalam prediksi. Semakin kecil nilai MAE, semakin baik kualitas model tersebut.

  Rumus MAE:

  MAE = (1/n) * Σ|i=1|^n |y_i - ŷ_i|

  Di mana:

  * n adalah jumlah sampel dalam data
  * y_i adalah nilai aktual
  * ŷ_i adalah nilai prediksi


  * Mean Squared Error (MSE)

  MSE adalah metode evaluasi lain yang digunakan dalam data science. MSE menghitung rata-rata dari selisih kuadrat antara nilai prediksi dan nilai aktual.

  Dengan kata lain, MSE menghitung berapa rata-rata kesalahan kuadrat dalam prediksi. Semakin kecil nilai MSE, semakin baik kualitas model tersebut.

  Rumus MSE:

  MSE = (1/n) * Σ|i=1|^n (y_i - ŷ_i)^2

  Di mana:

    * n adalah jumlah sampel dalam data
    * y_i adalah nilai aktual
    * ŷ_i adalah nilai prediks

Hasil evaluasi pada dataset training dan testing adalah sebagai berikut:
"""

for model_name, metrics in results.items():
    print(f"=== {model_name} ===")
    print(f"Train MAE: {metrics['Train MAE']:.4f}")
    print(f"Train MSE: {metrics['Train MSE']:.4f}")
    print(f"Test MAE: {metrics['Test MAE']:.4f}")
    print(f"Test MSE: {metrics['Test MSE']:.4f}\n")

"""Untuk memudahkan mari buat plot metrik tersebut dengan bar chart."""

import matplotlib.pyplot as plt
import numpy as np

# Data hasil evaluasi
models = list(results.keys())
train_mae = [results[model]['Train MAE'] for model in models]
train_mse = [results[model]['Train MSE'] for model in models]
test_mae = [results[model]['Test MAE'] for model in models]
test_mse = [results[model]['Test MSE'] for model in models]

# Plot MAE
x = np.arange(len(models))  # Posisi x untuk model
width = 0.35  # Lebar bar

fig, ax = plt.subplots(1, 2, figsize=(14, 6))

# Plot Train dan Test MAE
ax[0].bar(x - width/2, train_mae, width, label='Train MAE', color='skyblue')
ax[0].bar(x + width/2, test_mae, width, label='Test MAE', color='orange')
ax[0].set_title('Perbandingan MAE (Train vs Test)')
ax[0].set_xlabel('Model')
ax[0].set_ylabel('MAE')
ax[0].set_xticks(x)
ax[0].set_xticklabels(models)
ax[0].legend()

# Plot Train dan Test MSE
ax[1].bar(x - width/2, train_mse, width, label='Train MSE', color='skyblue')
ax[1].bar(x + width/2, test_mse, width, label='Test MSE', color='orange')
ax[1].set_title('Perbandingan MSE (Train vs Test)')
ax[1].set_xlabel('Model')
ax[1].set_ylabel('MSE')
ax[1].set_xticks(x)
ax[1].set_xticklabels(models)
ax[1].legend()

plt.tight_layout()
plt.show()

"""Dapat dilihat dari hasil visualisasi di atas bahwa algoritma Linear Regression merupakan model terbaik dibandingkan dengan algoritma lainnya. Linear Regression menunjukkan performa yang baik pada data test dan train, yang mengindikasikan bahwa model ini good fit. Sementara itu, kedua algoritma lainnya mengalami overfit."""